# Deep Learning - Redes Neuronales Profundas

Este directorio contiene recursos y trabajos relacionados con Deep Learning.

##  Temas Principales

### 1. Fundamentos de Redes Neuronales
- **Perceptr贸n y Multi-Layer Perceptron (MLP)**
  - Funciones de activaci贸n (ReLU, Sigmoid, Tanh, Softmax)
  - Forward propagation
  - Backpropagation
  - Gradient descent y variantes (SGD, Adam, RMSprop)

- **Regularizaci贸n**
  - Dropout
  - Batch Normalization
  - Layer Normalization
  - Weight Decay

- **Optimizaci贸n**
  - Learning rate scheduling
  - Gradient clipping
  - Early stopping
  - Inicializaci贸n de pesos (Xavier, He)

### 2. Redes Convolucionales (CNN)
- **Arquitecturas Cl谩sicas**
  - LeNet
  - AlexNet
  - VGG
  - ResNet
  - Inception
  - EfficientNet

- **Componentes**
  - Convolutional layers
  - Pooling layers
  - Fully connected layers
  - Skip connections

- **Aplicaciones**
  - Clasificaci贸n de im谩genes
  - Detecci贸n de objetos
  - Segmentaci贸n sem谩ntica
  - Transferencia de estilo

### 3. Redes Recurrentes (RNN)
- **Arquitecturas**
  - Vanilla RNN
  - LSTM (Long Short-Term Memory)
  - GRU (Gated Recurrent Unit)
  - Bidirectional RNN

- **Aplicaciones**
  - Predicci贸n de series temporales
  - Generaci贸n de texto
  - Traducci贸n autom谩tica
  - An谩lisis de sentimientos

### 4. Transformers
- **Arquitectura Transformer**
  - Self-attention mechanism
  - Multi-head attention
  - Positional encoding
  - Feed-forward networks

- **Modelos Populares**
  - BERT
  - GPT (GPT-2, GPT-3, GPT-4)
  - T5
  - Vision Transformers (ViT)

### 5. Autoencoders y GANs
- **Autoencoders**
  - Vanilla Autoencoders
  - Variational Autoencoders (VAE)
  - Denoising Autoencoders
  - Sparse Autoencoders

- **GANs (Generative Adversarial Networks)**
  - Vanilla GAN
  - DCGAN
  - StyleGAN
  - CycleGAN
  - Conditional GAN

##  Frameworks y Herramientas

### Principales Frameworks
- **TensorFlow/Keras**: Framework completo de Google
- **PyTorch**: Framework flexible y popular en investigaci贸n
- **JAX**: Computaci贸n num茅rica de alto rendimiento

### Herramientas de Soporte
- **TensorBoard**: Visualizaci贸n de entrenamiento
- **Weights & Biases (W&B)**: Tracking de experimentos
- **MLflow**: Gesti贸n del ciclo de vida de ML
- **ONNX**: Interoperabilidad entre frameworks

##  Recursos Recomendados

### Cursos
- [Deep Learning Specialization - Andrew Ng](https://www.coursera.org/specializations/deep-learning)
- [Fast.ai - Practical Deep Learning for Coders](https://course.fast.ai/)
- [CS231n - Stanford - Convolutional Neural Networks](http://cs231n.stanford.edu/)
- [CS224n - Stanford - Natural Language Processing with Deep Learning](http://web.stanford.edu/class/cs224n/)

### Libros
- "Deep Learning" - Ian Goodfellow, Yoshua Bengio, Aaron Courville
- "Neural Networks and Deep Learning" - Michael Nielsen
- "Dive into Deep Learning" - Aston Zhang et al.

### Papers Fundamentales
- "ImageNet Classification with Deep Convolutional Neural Networks" (AlexNet)
- "Very Deep Convolutional Networks for Large-Scale Image Recognition" (VGG)
- "Deep Residual Learning for Image Recognition" (ResNet)
- "Attention Is All You Need" (Transformer)
- "Generative Adversarial Networks" (GAN)

##  Proyectos Sugeridos

1. **Clasificaci贸n de MNIST/CIFAR-10**: Introducci贸n a CNNs
2. **Transfer Learning con ImageNet**: Usar modelos pre-entrenados
3. **Generaci贸n de Texto con RNN/LSTM**: Crear un generador de texto
4. **Chatbot con Seq2Seq**: Modelo encoder-decoder
5. **Style Transfer**: Transferencia de estilo art铆stico
6. **Face Generation con GAN**: Generar rostros sint茅ticos
7. **Object Detection con YOLO**: Detecci贸n de objetos en tiempo real
8. **Fine-tuning de BERT**: Clasificaci贸n de texto

##  Recursos Computacionales

### Cloud Platforms
- **Google Colab**: GPUs gratuitas para prototipado
- **Kaggle Kernels**: GPUs gratuitas con l铆mites
- **AWS SageMaker**: Infraestructura profesional
- **Google Cloud AI Platform**: Servicios de ML escalables
- **Azure Machine Learning**: Plataforma empresarial

### Hardware Recomendado
- GPU NVIDIA (GTX 1080 Ti, RTX 3090, A100 para entrenamiento serio)
- RAM: M铆nimo 16GB, recomendado 32GB+
- Almacenamiento SSD para datasets grandes

##  Best Practices

1. **Comienza simple**: Prueba primero con modelos peque帽os
2. **Data augmentation**: Aumenta tu dataset para mejor generalizaci贸n
3. **Transfer learning**: No reinventes la rueda, usa modelos pre-entrenados
4. **Monitorea overfitting**: Usa validation set y early stopping
5. **Experimenta con hiperpar谩metros**: Learning rate, batch size, arquitectura
6. **Visualiza tu red**: Entiende qu茅 aprende cada capa
7. **Usa checkpoints**: Guarda modelos peri贸dicamente durante el entrenamiento
8. **Mixed precision training**: Acelera el entrenamiento con FP16

##  Datasets Populares

### Im谩genes
- ImageNet
- COCO (Common Objects in Context)
- CIFAR-10/CIFAR-100
- MNIST/Fashion-MNIST

### Texto
- Wikipedia dump
- Common Crawl
- BookCorpus
- OpenWebText

### Multimodal
- MS COCO (im谩genes con captions)
- Visual Question Answering (VQA)
- Conceptual Captions

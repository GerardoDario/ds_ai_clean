# Reinforcement Learning - Aprendizaje por Refuerzo

Este directorio contiene recursos y trabajos relacionados con Reinforcement Learning.

##  Temas Principales

### 1. Fundamentos
- **Conceptos B谩sicos**
  - Agent, Environment, State, Action, Reward
  - Policy (): estrategia del agente
  - Value Function: V(s) y Q(s,a)
  - Model-based vs Model-free
  - On-policy vs Off-policy

- **Markov Decision Process (MDP)**
  - Estados, acciones, transiciones
  - Recompensas y retornos
  - Factor de descuento (纬)
  - Bellman Equations

### 2. M茅todos Tabulares
- **Dynamic Programming**
  - Policy Iteration
  - Value Iteration
  - Policy Evaluation

- **Monte Carlo Methods**
  - First-visit MC
  - Every-visit MC
  - MC Control
  - Exploring Starts

- **Temporal-Difference (TD) Learning**
  - TD(0)
  - SARSA (State-Action-Reward-State-Action)
  - Q-Learning
  - Expected SARSA

- **n-step Bootstrapping**
  - n-step TD
  - n-step SARSA
  - n-step Q-Learning

### 3. Value-Based Deep RL
- **Deep Q-Networks (DQN)**
  - Experience Replay
  - Target Networks
  - Variantes:
    - Double DQN
    - Dueling DQN
    - Prioritized Experience Replay
    - Rainbow DQN
    - Noisy DQN

### 4. Policy-Based Methods
- **Policy Gradient**
  - REINFORCE
  - Baseline methods
  - Actor-Critic
  - Advantage function

- **Advanced Policy Gradient**
  - **A3C** (Asynchronous Advantage Actor-Critic)
  - **A2C** (Advantage Actor-Critic)
  - **PPO** (Proximal Policy Optimization)
  - **TRPO** (Trust Region Policy Optimization)

### 5. Actor-Critic Methods
- **Deterministic Policy Gradient**
  - **DDPG** (Deep Deterministic Policy Gradient)
  - **TD3** (Twin Delayed DDPG)

- **Soft Actor-Critic (SAC)**
  - Maximum entropy RL
  - Off-policy learning

### 6. Model-Based RL
- **World Models**
  - Learning environment dynamics
  - Planning in learned models

- **Dyna-Q**
  - Planning and learning
  - Simulated experience

- **AlphaZero/MuZero**
  - Monte Carlo Tree Search (MCTS)
  - Self-play

### 7. Multi-Agent RL
- Cooperative agents
- Competitive agents
- Mixed scenarios
- QMIX, MADDPG

### 8. Inverse RL y Imitation Learning
- Learning from demonstrations
- Behavioral cloning
- Inverse Reinforcement Learning
- GAIL (Generative Adversarial Imitation Learning)

### 9. Hierarchical RL
- Options framework
- Feudal Networks
- Goal-conditioned RL

##  Herramientas y Bibliotecas

### Entornos de Simulaci贸n
- **OpenAI Gym**: Est谩ndar de facto para RL
- **Gymnasium**: Fork mantenido de Gym
- **Unity ML-Agents**: Entornos 3D
- **MuJoCo**: F铆sica para rob贸tica
- **PyBullet**: F铆sica de c贸digo abierto
- **Atari**: Juegos cl谩sicos de Atari
- **PettingZoo**: Multi-agent environments

### Bibliotecas de RL
- **Stable-Baselines3**: Implementaciones de algoritmos populares (PyTorch)
- **RLlib (Ray)**: RL escalable y distribuido
- **TF-Agents**: TensorFlow para RL
- **Dopamine**: Framework de Google para investigaci贸n
- **CleanRL**: Implementaciones simples y limpias
- **Spinning Up (OpenAI)**: Recursos educativos

### Herramientas de Visualizaci贸n
- **TensorBoard**: Monitoreo de entrenamiento
- **Weights & Biases**: Tracking de experimentos
- **Gym Monitor**: Grabaci贸n de episodios

##  Recursos Recomendados

### Cursos
- [CS285 - Deep Reinforcement Learning (UC Berkeley)](http://rail.eecs.berkeley.edu/deeprlcourse/)
- [David Silver's RL Course (DeepMind)](https://www.davidsilver.uk/teaching/)
- [Spinning Up in Deep RL (OpenAI)](https://spinningup.openai.com/)
- [Coursera - Reinforcement Learning Specialization](https://www.coursera.org/specializations/reinforcement-learning)

### Libros
- **"Reinforcement Learning: An Introduction" - Sutton & Barto** (La biblia del RL)
- "Deep Reinforcement Learning Hands-On" - Maxim Lapan
- "Foundations of Deep Reinforcement Learning" - Laura Graesser, Wah Loon Keng
- "Algorithms for Reinforcement Learning" - Csaba Szepesv谩ri

### Papers Fundamentales
- "Playing Atari with Deep Reinforcement Learning" (DQN, 2013)
- "Human-level control through deep reinforcement learning" (Nature DQN, 2015)
- "Continuous control with deep reinforcement learning" (DDPG, 2015)
- "Asynchronous Methods for Deep Reinforcement Learning" (A3C, 2016)
- "Proximal Policy Optimization Algorithms" (PPO, 2017)
- "Mastering the game of Go with deep neural networks" (AlphaGo, 2016)
- "Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model" (MuZero, 2019)

### Blogs y Recursos
- [OpenAI Blog - RL Section](https://openai.com/blog/tags/reinforcement-learning/)
- [DeepMind Blog](https://deepmind.com/blog)
- [Lil'Log - RL Posts](https://lilianweng.github.io/lil-log/)
- [Distill.pub - RL Articles](https://distill.pub/)

##  Proyectos Sugeridos

### Principiantes
1. **CartPole**: Balance de p茅ndulo invertido
2. **Mountain Car**: Carro en una colina
3. **Frozen Lake**: Grid world simple
4. **Taxi**: Navegaci贸n y pickup/dropoff

### Intermedios
5. **LunarLander**: Control continuo
6. **Atari Games**: Breakout, Pong, Space Invaders
7. **BipedalWalker**: Locomoci贸n
8. **Custom Grid Worlds**: Crear tus propios entornos

### Avanzados
9. **Multi-Agent Soccer**: Coordinaci贸n de equipos
10. **Robotic Manipulation**: Brazo rob贸tico con MuJoCo
11. **Trading Bot**: RL para trading algor铆tmico
12. **Autonomous Driving**: Simulaci贸n de conducci贸n
13. **Dota 2/StarCraft II**: RL en juegos complejos

##  Entornos Populares

### Cl谩sicos
- CartPole-v1
- MountainCar-v0
- Acrobot-v1
- Pendulum-v1

### Atari
- Breakout
- Pong
- Space Invaders
- Pac-Man

### Control Continuo
- LunarLander
- BipedalWalker
- HalfCheetah (MuJoCo)
- Ant (MuJoCo)
- Humanoid (MuJoCo)

### Rob贸tica
- FetchReach
- HandManipulate
- ShadowHand

##  Best Practices

1. **Empieza simple**: Usa CartPole antes de Atari
2. **Hyperparameter tuning**: RL es muy sensible a hiperpar谩metros
3. **Semilla aleatoria**: Usa m煤ltiples seeds para evaluaci贸n
4. **Monitoreo**: Tracking de recompensas, loss, entrop铆a
5. **Normalizaci贸n**: Normaliza observaciones y recompensas
6. **Debugging**: RL es dif铆cil de debuggear, empieza con implementaciones probadas
7. **Evaluation**: Separa entrenamiento de evaluaci贸n
8. **Paciencia**: RL requiere mucho tiempo de entrenamiento
9. **Baseline**: Compara con algoritmos establecidos
10. **Reproducibilidad**: Documenta seeds, hiperpar谩metros, c贸digo

##  Aplicaciones del Mundo Real

### Rob贸tica
- Manipulaci贸n de objetos
- Locomoci贸n
- Navegaci贸n aut贸noma
- Assembly tasks

### Juegos
- AlphaGo, AlphaZero
- Dota 2 (OpenAI Five)
- StarCraft II (AlphaStar)

### Finanzas
- Trading algor铆tmico
- Portfolio management
- Option pricing

### Sistemas de Recomendaci贸n
- Personalizaci贸n de contenido
- Ad placement
- News recommendation

### Recursos y Energ铆a
- Control de HVAC
- Grid optimization
- Resource allocation

### Salud
- Treatment planning
- Drug discovery
- Personalized medicine

##  Tendencias Actuales

- **Offline RL**: Aprender de datos hist贸ricos sin interacci贸n
- **Meta-RL**: Aprender a aprender
- **World Models**: Modelos generativos del entorno
- **Sim-to-Real**: Transferencia de simulaci贸n a mundo real
- **Safe RL**: RL con restricciones de seguridad
- **Multi-task RL**: Un agente, m煤ltiples tareas
- **Explainable RL**: Interpretabilidad de pol铆ticas
- **Sample Efficiency**: Reducir muestras necesarias

## 锔 Desaf铆os Comunes

1. **Sample Inefficiency**: Millones de pasos de entrenamiento
2. **Inestabilidad**: Colapso del entrenamiento
3. **Sensibilidad a hiperpar谩metros**: Peque帽os cambios, grandes efectos
4. **Reproducibilidad**: Resultados variables entre runs
5. **Credit Assignment**: Asignar cr茅dito a acciones pasadas
6. **Exploration vs Exploitation**: Balance dif铆cil
7. **Sparse Rewards**: Se帽ales de aprendizaje infrecuentes
8. **Transferencia**: Modelos espec铆ficos a entornos
